{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: 3 W: 5\n",
      "M: 3 N: 3\n",
      "[[219. 264. 309.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "x = np.array([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8 ,9, 10],\n",
    "    [11, 12, 13, 14, 15]\n",
    "])\n",
    "\n",
    "k = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "\n",
    "# Define convolution function\n",
    "def convo2d(input, kernel):\n",
    "    H,W = input.shape\n",
    "    print(f\"H: {H}\", f\"W: {W}\")\n",
    "    M,N = kernel.shape\n",
    "    print(f\"M: {M}\", f\"N: {N}\")\n",
    "    out = np.zeros((H-M+1,W-N+1), dtype=float)\n",
    "    kernel = np.flip(kernel)\n",
    "    for i in range(H-M+1):\n",
    "        for j in range(W-N+1):\n",
    "            out[i,j] = np.sum( input[i:i+M,j:j+N] * kernel)\n",
    "    return out\n",
    "\n",
    "o = convo2d(x, k)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr: [[4. 4. 4. 4. 1. 1. 1. 1.]\n",
      " [4. 4. 4. 4. 1. 1. 1. 1.]\n",
      " [4. 4. 4. 4. 1. 1. 1. 1.]\n",
      " [4. 4. 4. 4. 1. 1. 1. 1.]\n",
      " [4. 4. 4. 4. 1. 1. 1. 1.]\n",
      " [4. 4. 4. 4. 1. 1. 1. 1.]\n",
      " [4. 4. 4. 4. 1. 1. 1. 1.]\n",
      " [4. 4. 4. 4. 1. 1. 1. 1.]]\n",
      "ker: [[-1.  0.  1.]\n",
      " [-1.  0.  1.]\n",
      " [-1.  0.  1.]]\n",
      "out: tensor([[[[ 0.,  0., -9., -9.,  0.,  0.],\n",
      "          [ 0.,  0., -9., -9.,  0.,  0.],\n",
      "          [ 0.,  0., -9., -9.,  0.,  0.],\n",
      "          [ 0.,  0., -9., -9.,  0.,  0.],\n",
      "          [ 0.,  0., -9., -9.,  0.,  0.],\n",
      "          [ 0.,  0., -9., -9.,  0.,  0.]]]], dtype=torch.float64)\n",
      "out.shape: torch.Size([1, 1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# Create 8 x 8 tensor with half 4s, half 1s\n",
    "arr = np.zeros((8, 8), dtype=float)\n",
    "arr[:,:4] = 4.0\n",
    "arr[:,4:] = 1.0\n",
    "print(\"arr:\", arr)\n",
    "\n",
    "# Create 3 x 3 kernel with [-1, 0, 1] for each row\n",
    "ker = np.zeros((3, 3), dtype=float)\n",
    "ker[:,:1] = -1.0\n",
    "ker[:,2:] = 1.0\n",
    "print(\"ker:\", ker)\n",
    "\n",
    "# Make into tensor and unsqueeze to change shape from (8, 8) to (1, 1, 8, 8) for input to match \n",
    "# (batch_size, num_input_channels, image_height, image_width)\n",
    "arr = torch.from_numpy(arr)\n",
    "arr = torch.unsqueeze(arr, 0)\n",
    "arr = torch.unsqueeze(arr, 0)\n",
    "\n",
    "# Do the same for the kernel to change shape from (3, 3) to (1, 1, 3, 3) to match\n",
    "# (out_channels, in_channels, kernel_height, kernel_width)\n",
    "ker = torch.from_numpy(ker)\n",
    "ker = torch.unsqueeze(ker, 0)\n",
    "ker = torch.unsqueeze(ker, 0)\n",
    "\n",
    "out = torch.nn.functional.conv2d(arr, ker, stride=1)\n",
    "print(\"out:\", out)\n",
    "print(\"out.shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with classes instead of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0618, -0.3360, -1.4161,  0.1578,  0.3603, -1.1822, -0.9412,\n",
      "            0.6454],\n",
      "          [ 0.5408, -1.7552, -0.7583, -0.2435,  1.3099,  1.8129, -0.2258,\n",
      "            0.1054],\n",
      "          [-1.5631,  0.1750, -0.1093,  1.2586,  0.8260,  0.9647,  0.3008,\n",
      "           -1.4056],\n",
      "          [-0.5501,  0.5267,  1.3969, -1.2911, -0.0650,  0.2992,  0.4321,\n",
      "           -2.1099],\n",
      "          [-0.3377, -0.3679, -0.5889, -0.9092,  0.6957, -0.4958,  0.5461,\n",
      "            0.2581],\n",
      "          [-0.8905, -1.2597,  1.0387,  0.0769, -0.4658, -0.7012,  0.3702,\n",
      "            0.0983],\n",
      "          [-0.4355,  0.3719, -0.8343,  0.3197, -0.6816,  0.9041,  1.7628,\n",
      "           -1.3260],\n",
      "          [ 0.2247, -1.4334, -0.4431,  0.4050, -1.2078, -1.5878, -0.1956,\n",
      "            2.2635]]]])\n",
      "torch.Size([1, 1, 8, 8])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "# Required args for Conv2d class are (in_channels, out_channels, kernel_size)\n",
    "# Kernel size can be scalar for square kernels, tuple for nonsquare\n",
    "# Input tensor must have 4 axes: (batch_size, in_channels, H, W)\n",
    "\n",
    "# Create Convolution 2d layer with 1 in_channel, 1 out_channel, and kernel_size 3 respectively\n",
    "conop = nn.Conv2d(1, 1, 3, bias=False) ## assumes a stride of 1\n",
    "\n",
    "# Random 1 x 1 x 8 x 8 tensor (remember that's 4 axes but 1 * 1 * 8 * 8 = 64 dimensions per sample)\n",
    "input = torch.randn(1, 1, 8, 8)\n",
    "print(input)\n",
    "print(input.shape)\n",
    "print(input.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1636,  0.3696, -0.4037,  0.0316,  0.3237, -0.2373],\n",
      "          [ 0.8393,  0.1395,  0.0454, -0.7921, -0.4253,  0.7620],\n",
      "          [ 0.0601,  0.3040, -1.2482,  0.5007, -0.2265,  0.0976],\n",
      "          [-0.6007, -0.2193,  0.8332,  0.2552, -0.4785,  0.3211],\n",
      "          [ 0.3870,  0.5986,  0.0270, -0.7675, -0.1456,  0.2733],\n",
      "          [ 0.3963, -0.8957,  0.8574,  0.4402,  0.6020, -0.8086]]]],\n",
      "       grad_fn=<ThnnConv2DBackward>)\n",
      "torch.Size([1, 1, 6, 6])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Pass input through Conv2d layer\n",
    "output = conop(input)\n",
    "\n",
    "print(output)\n",
    "print(output.shape)\n",
    "print(output.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.2275, -0.3114, -0.0669],\n",
      "          [-0.2838,  0.1715,  0.0298],\n",
      "          [-0.0457, -0.0035, -0.2681]]]], requires_grad=True)\n",
      "torch.Size([1, 1, 3, 3])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# We can examine the learned kernel weights\n",
    "ker = conop.weight\n",
    "\n",
    "print(ker)\n",
    "print(ker.shape)\n",
    "print(ker.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
